{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83bc62aa",
   "metadata": {},
   "source": [
    "  \n",
    "#   1  Model Deployment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e8c800",
   "metadata": {},
   "source": [
    " \n",
    "##   2  Objective and Function Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadff8c2",
   "metadata": {},
   "source": [
    "The objective of this notebook is to develop deployment API for the best performing ML model.   The functions are\n",
    "-  process_data\n",
    "-  regr_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef8239a",
   "metadata": {},
   "source": [
    "### process_data(in_point)    \n",
    "__input__ : csv file with sample  data point(s).   \n",
    "__output__ : predictions for the input data.     \n",
    "__processing__: This function takes the input data sample and produces prediction for the input data.The input data is pre-processed to handle nulls.Then helper functions perform feature engineering to get additional features. These features undergo feature transformation. The transformed features are used to compute the final prediction.    \n",
    "__display__: The functions has display for process time "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a16c4b8",
   "metadata": {},
   "source": [
    "### regr_metric(test_sampl,y_pred)\n",
    "__input__ : input data ,model preiction.   \n",
    "__output__ : model metrics  mean_squared_error and mean_absolute_error.     \n",
    "__processing__: This function takes input data sample and model prediction for this data.Using these two inputs this function computes the metrics for the regression model like mean_squared_error and mean_absolute_error.    \n",
    "__display__:   mean_squared_error , mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9196e791",
   "metadata": {},
   "source": [
    " \n",
    "##   3  Create input data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41bc6118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import seaborn as sns#Plots\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "# Hyperparameter tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn import metrics \n",
    "from sklearn.externals import joblib\n",
    "# Import label encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6678dbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.53 s, sys: 89.1 ms, total: 1.62 s\n",
      "Wall time: 1.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# extract single data point from data\n",
    "test_clean = pd.read_csv('test_clean.csv',converters={\"fullVisitorId\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc517b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_point = test_clean.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1955ee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data to file \n",
    "in_point.to_csv('in_point.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "360c75a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channelGrouping</th>\n",
       "      <th>date</th>\n",
       "      <th>fullVisitorId</th>\n",
       "      <th>visitId</th>\n",
       "      <th>visitNumber</th>\n",
       "      <th>visitStartTime</th>\n",
       "      <th>device.browser</th>\n",
       "      <th>device.operatingSystem</th>\n",
       "      <th>device.isMobile</th>\n",
       "      <th>device.deviceCategory</th>\n",
       "      <th>...</th>\n",
       "      <th>totals.timeOnSite</th>\n",
       "      <th>totals.sessionQualityDim</th>\n",
       "      <th>totals.transactions</th>\n",
       "      <th>totals.transactionRevenue</th>\n",
       "      <th>totals.totalTransactionRevenue</th>\n",
       "      <th>trafficSource.referralPath</th>\n",
       "      <th>trafficSource.campaign</th>\n",
       "      <th>trafficSource.source</th>\n",
       "      <th>trafficSource.medium</th>\n",
       "      <th>trafficSource.keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Organic Search</td>\n",
       "      <td>20180511</td>\n",
       "      <td>7460955084541987166</td>\n",
       "      <td>1526099341</td>\n",
       "      <td>2</td>\n",
       "      <td>1526099341</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Android</td>\n",
       "      <td>True</td>\n",
       "      <td>mobile</td>\n",
       "      <td>...</td>\n",
       "      <td>973.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>google</td>\n",
       "      <td>organic</td>\n",
       "      <td>(not provided)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  channelGrouping      date        fullVisitorId     visitId  visitNumber  \\\n",
       "0  Organic Search  20180511  7460955084541987166  1526099341            2   \n",
       "\n",
       "   visitStartTime device.browser device.operatingSystem  device.isMobile  \\\n",
       "0      1526099341         Chrome                Android             True   \n",
       "\n",
       "  device.deviceCategory  ... totals.timeOnSite totals.sessionQualityDim  \\\n",
       "0                mobile  ...             973.0                        1   \n",
       "\n",
       "  totals.transactions totals.transactionRevenue  \\\n",
       "0                 NaN                       NaN   \n",
       "\n",
       "  totals.totalTransactionRevenue trafficSource.referralPath  \\\n",
       "0                            NaN                  (not set)   \n",
       "\n",
       "  trafficSource.campaign  trafficSource.source  trafficSource.medium  \\\n",
       "0              (not set)                google               organic   \n",
       "\n",
       "   trafficSource.keyword  \n",
       "0         (not provided)  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9235c3db",
   "metadata": {},
   "source": [
    "##   4 process_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d65561",
   "metadata": {},
   "source": [
    "##   4.1  helper functions for process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7dddb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_cat(indata):\n",
    "    '''\n",
    "    encode categorical features\n",
    "    '''\n",
    "    # categorical features\n",
    "    cat_cols =  ['channelGrouping', 'device.browser', 'device.operatingSystem',\n",
    "                 'device.deviceCategory',  'geoNetwork.continent', 'geoNetwork.subContinent',\n",
    "                 'geoNetwork.country',  'geoNetwork.region',  'geoNetwork.metro',\n",
    "                 'geoNetwork.city', 'geoNetwork.networkDomain', 'trafficSource.campaign',\n",
    "                 'trafficSource.source',  'trafficSource.medium', 'trafficSource.keyword',\n",
    "                 'trafficSource.referralPath',\n",
    "                 'browser_category', 'browser_os','source_country',\n",
    "                 'channelGrouping_browser','channelGrouping_OS']\n",
    "    for col in cat_cols: \n",
    "        labelencoder = LabelEncoder()\n",
    "        indata[col] = labelencoder.fit_transform(indata[col].values.astype('str' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b02229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/robikscube/tutorial-time-series-forecasting-with-xgboost\n",
    "def transform_date_int(indata):\n",
    "    \"\"\"\n",
    "    Create temporal features from date fields\n",
    "    \"\"\"\n",
    "    indata['date'] = pd.to_datetime(indata['date'])\n",
    "    indata['dayofweek'] = indata['date'].dt.dayofweek \n",
    "    indata['quarter'] = indata['date'].dt.quarter \n",
    "    indata['month'] = indata['date'].dt.month \n",
    "    indata['year'] = indata['date'].dt.year \n",
    "    indata['dayofyear'] = indata['date'].dt.dayofyear \n",
    "    indata['dayofmonth'] = indata['date'].dt.day \n",
    "    indata['weekofyear'] = indata['date'].dt.isocalendar().week.astype(float)\n",
    "    #features for visitStartTime\n",
    "    indata['vis_date'] = pd.to_datetime(indata['visitStartTime'], unit='s')\n",
    "    indata['sess_date_hours'] = indata['vis_date'].dt.hour \n",
    "    #https://www.kaggle.com/ashishpatel26/permutation-importance-feature-imp-measure-gacrp/notebook\n",
    "    indata['hits_per_day']   = indata.groupby('dayofyear')['totals.hits'].transform('nunique') \n",
    "    indata['hits_per_month'] = indata.groupby('month')['totals.hits'].transform('nunique') \n",
    "    indata['hits_per_dom'] = indata.groupby('dayofmonth')['totals.hits'].transform('nunique') \n",
    "    indata['hits_per_dow'] = indata.groupby('dayofweek')['totals.hits'].transform('nunique') \n",
    "    indata['pageviews_per_day'] = indata.groupby('dayofyear')['totals.pageviews'].transform('nunique') \n",
    "    indata['pageviews_per_month'] = indata.groupby('month')['totals.pageviews'].transform('nunique') \n",
    "    indata['pageviews_per_dom'] = indata.groupby('dayofmonth')['totals.pageviews'].transform('nunique') \n",
    "    indata['pageviews_per_dow'] = indata.groupby('dayofweek')['totals.pageviews'].transform('nunique') \n",
    "    indata['month_unique_user_count'] = indata.groupby('month')['fullVisitorId'].transform('nunique')\n",
    "    indata['day_unique_user_count'] = indata.groupby('dayofyear')['fullVisitorId'].transform('nunique')\n",
    "    indata['weekday_unique_user_count'] = indata.groupby('dayofweek')['fullVisitorId'].transform('nunique')\n",
    "    indata['monthday_unique_user_count'] = indata.groupby('dayofmonth')['fullVisitorId'].transform('nunique') \n",
    "    indata['browser_category'] = indata['device.browser'] + '_' + indata['device.deviceCategory']\n",
    "    indata['browser_os'] = indata['device.browser'] + '_' + indata['device.operatingSystem']\n",
    "    indata['source_country'] = indata['trafficSource.source'] + '_' + indata['geoNetwork.country']\n",
    "    indata['channelGrouping_browser'] = indata['device.browser'] + \"_\" + indata['channelGrouping']\n",
    "    indata['channelGrouping_OS'] = indata['device.operatingSystem'] + \"_\" + indata['channelGrouping']\n",
    "    indata['tran_per_day']   = indata.groupby('dayofyear')['totals.transactions'].transform('nunique') \n",
    "    indata['tran_per_month'] = indata.groupby('month')['totals.transactions'].transform('nunique') \n",
    "    indata['tran_per_dom'] = indata.groupby('dayofmonth')['totals.transactions'].transform('nunique') \n",
    "    indata['tran_per_dow'] = indata.groupby('dayofweek')['totals.transactions'].transform('nunique') \n",
    "    indata['timeOnSite_per_day']   = indata.groupby('dayofyear')['totals.timeOnSite'].transform('nunique') \n",
    "    indata['timeOnSite_per_month'] = indata.groupby('month')['totals.timeOnSite'].transform('nunique') \n",
    "    indata['timeOnSite_per_dom'] = indata.groupby('dayofmonth')['totals.timeOnSite'].transform('nunique') \n",
    "    indata['timeOnSite_per_dow'] = indata.groupby('dayofweek')['totals.timeOnSite'].transform('nunique') \n",
    "    \n",
    "    #convert int to float to avoid truncations\n",
    "    for col in indata.columns:\n",
    "        if indata[col].dtype == 'int64':   \n",
    "           indata[col] = indata[col].astype(float)\n",
    "    return indata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98a3010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transform(indata):\n",
    "    '''\n",
    "    transform user level features\n",
    "    '''\n",
    "    #https://stackoverflow.com/questions/19078325/naming-returned-columns-in-pandas-aggregate-function\n",
    "    def diff(x):\n",
    "      #get difference between max & min date  \n",
    "      time_d =  x.max() -x.min() \n",
    "      return float(time_d.days)\n",
    "    #https://stackoverflow.com/questions/17071871/how-do-i-select-rows-from-a-dataframe-based-on-column-values  \n",
    "    def vcount(x):\n",
    "      #get count of rows for visitStartTime\n",
    "      return len(indata.loc[indata['visitStartTime'].isin(x)])\n",
    "    #\n",
    "    date_min= min(indata['date'])\n",
    "    date_max= max(indata['date'])   \n",
    "    # difference between preiod start and first visit\n",
    "    def min_diff(x):\n",
    "      time_d= x.min() - date_min\n",
    "      return float(time_d.days)\n",
    "    # difference between preiod end and last visit\n",
    "    def max_diff(x):\n",
    "      time_d=  date_max - x.max()\n",
    "      return float(time_d.days)\n",
    "        \n",
    "\n",
    "    dfg=indata.groupby('fullVisitorId').agg({ \n",
    "    'channelGrouping'             : ['max'],              \n",
    "    'device.browser'              : 'max',                   \n",
    "    'device.operatingSystem'      : 'max',                     \n",
    "    'device.isMobile'             : 'max',      \n",
    "    'device.deviceCategory'       : 'max',                      \n",
    "    'geoNetwork.continent'        : 'max',                      \n",
    "    'geoNetwork.subContinent'     : 'max',                        \n",
    "    'geoNetwork.country'          : 'max',                       \n",
    "    'geoNetwork.region'           : 'max',                        \n",
    "    'geoNetwork.metro'            : 'max',                          \n",
    "    'geoNetwork.city'             : 'max',                         \n",
    "    'geoNetwork.networkDomain'    : 'max',                          \n",
    "    'trafficSource.campaign'      : 'max',                         \n",
    "    'trafficSource.source'        : 'max',                          \n",
    "    'trafficSource.medium'        : 'max',                         \n",
    "    'trafficSource.keyword'       : 'max',                          \n",
    "    'trafficSource.referralPath'  : 'max',                         \n",
    "    'date'                      : [('_diff', diff),('_min',min_diff),('_max',max_diff)], \n",
    "    'visitStartTime'            : [('_count', vcount)],                    \n",
    "    'totals.hits'               : [ 'max', 'min', 'sum','mean'],    \n",
    "    'totals.pageviews'          : ['max', 'min', 'sum','mean'],\n",
    "    'totals.timeOnSite'         : ['max', 'min', 'sum','mean'], \n",
    "    'totals.sessionQualityDim'  : 'max',\n",
    "    'totals.transactions'       : 'sum',                \n",
    "    'totals.transactionRevenue' : 'sum',               \n",
    "    'totals.totalTransactionRevenue' :  'sum',\n",
    "    'dayofweek'                 :  [ 'max', 'min'],                \n",
    "    'quarter'                   :  [ 'max', 'min'],                                \n",
    "    'month'                     :  [ 'max', 'min'],                                   \n",
    "    'year'                      :  [ 'max', 'min'],                                 \n",
    "    'dayofyear'                 :  [ 'max', 'min'],                                 \n",
    "    'dayofmonth'                :  [ 'max', 'min'],                                   \n",
    "    'weekofyear'                :  [ 'max', 'min'],      \n",
    "    'sess_date_hours'           :  [ 'max', 'min', 'sum','mean'],\n",
    "    'hits_per_day'              :  [ 'max', 'min', 'sum','mean'],   \n",
    "    'hits_per_month'            :  [ 'max', 'min', 'sum','mean'],    \n",
    "    'hits_per_dom'              :  [ 'max', 'min', 'sum','mean'],    \n",
    "    'hits_per_dow'              :  [ 'max', 'min', 'sum','mean'],    \n",
    "    'pageviews_per_day'         :  [ 'max', 'min', 'sum','mean'], \n",
    "    'pageviews_per_month'       :  [ 'max', 'min', 'sum','mean'], \n",
    "    'pageviews_per_dom'         :  [ 'max', 'min', 'sum','mean'], \n",
    "    'pageviews_per_dow'         :  [ 'max', 'min', 'sum','mean'], \n",
    "    'month_unique_user_count'   :  [ 'max', 'min', 'sum','mean'],    \n",
    "    'day_unique_user_count'     :  [ 'max', 'min', 'sum','mean'],    \n",
    "    'weekday_unique_user_count' :  [ 'max', 'min', 'sum','mean'],    \n",
    "    'monthday_unique_user_count' :  [ 'max', 'min', 'sum','mean'],    \n",
    "    'browser_category'          : 'max', \n",
    "    'browser_os'                : 'max',\n",
    "    'source_country'            : 'max',   \n",
    "    'channelGrouping_browser'   : 'max',   \n",
    "    'channelGrouping_OS'        : 'max',   \n",
    "    'tran_per_day'              :  [ 'max', 'min', 'sum','mean'],   \n",
    "    'tran_per_month'            :  [ 'max', 'min', 'sum','mean'],  \n",
    "    'tran_per_dom'              :  [ 'max', 'min', 'sum','mean'],  \n",
    "    'tran_per_dow'              :  [ 'max', 'min', 'sum','mean'],  \n",
    "    'timeOnSite_per_day'        :  [ 'max', 'min', 'sum','mean'],   \n",
    "    'timeOnSite_per_month'      :  [ 'max', 'min', 'sum','mean'],  \n",
    "    'timeOnSite_per_dom'        :  [ 'max', 'min', 'sum','mean'],  \n",
    "    'timeOnSite_per_dow'        :  [ 'max', 'min', 'sum','mean']  \n",
    "     \n",
    "        \n",
    "    })\n",
    "    #rename column by appending the aggregate name\n",
    "    dfg.columns = [\"_\".join(x) for x in dfg.columns.ravel()]\n",
    "    return dfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcde813c",
   "metadata": {},
   "source": [
    "##    4.2  process_data() function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e80af6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(test_data):\n",
    "    '''\n",
    "    process input query point and compute predicted value\n",
    "    '''\n",
    "    start = time.process_time()\n",
    "    #-----------------------------------\n",
    "    #load saved models using joblib\n",
    "    cat_cols =  ['channelGrouping', 'device.browser', 'device.operatingSystem',\n",
    "                 'device.deviceCategory',  'geoNetwork.continent', 'geoNetwork.subContinent',\n",
    "                 'geoNetwork.country',  'geoNetwork.region',  'geoNetwork.metro',\n",
    "                 'geoNetwork.city', 'geoNetwork.networkDomain', 'trafficSource.campaign',\n",
    "                 'trafficSource.source',  'trafficSource.medium', 'trafficSource.keyword',\n",
    "                 'trafficSource.referralPath',\n",
    "                 'browser_category', 'browser_os','source_country',\n",
    "                 'channelGrouping_browser','channelGrouping_OS']\n",
    "    lbgclf = joblib.load('pkllbgclf')\n",
    "    lbgreg = joblib.load('pkllbgreg')\n",
    "    for col in cat_cols:\n",
    "        model =  'le' + col\n",
    "        pkl_fl = 'pkl' + col\n",
    "        model = joblib.load(pkl_fl)\n",
    "    #-----------------------------------\n",
    "    #pre-processing data\n",
    "    #handle boolean data\n",
    "    test_data['device.isMobile'] = test_data['device.isMobile'].astype(bool)\n",
    "    #handle numeric data for nulls\n",
    "    #numeric features\n",
    "    num_cols =  ['visitId','visitNumber','visitStartTime',\n",
    "                 'totals.hits','totals.pageviews','totals.sessionQualityDim',\n",
    "                 'totals.timeOnSite','totals.transactions','totals.transactionRevenue',\n",
    "                 'totals.totalTransactionRevenue']\n",
    "    null_cols = in_point[in_point.columns[in_point.isna().any()]]\n",
    "    for col in num_cols:\n",
    "        test_data[col] = test_data[col].astype('float')\n",
    "        if  col in null_cols:\n",
    "            test_data[col] =0          # replace nulls with zeros\n",
    "            \n",
    "    #-----------------------------------     \n",
    "    #feature transforms\n",
    "    test_data = transform_date_int(test_data)\n",
    "    transform_cat(test_data)\n",
    "    trans_data =  data_transform(test_data)\n",
    "    #add missing column\n",
    "    trans_data['fullVisitorId'] = 0\n",
    "    trans_data= trans_data.drop('totals.totalTransactionRevenue_sum',axis=1)\n",
    "    #-----------------------------------\n",
    "    target_cols= [ 'fullVisitorId']\n",
    "    #Predicting  on test data\n",
    "    classifier_pred = lbgclf.predict_proba(trans_data.drop(target_cols,axis=1))\n",
    "    regressor_pred = lbgreg.predict(trans_data.drop(target_cols,axis=1))\n",
    "    final_pred = (classifier_pred[:,1]*regressor_pred)\n",
    "    elapsed_time = time.process_time() - start\n",
    "    print('time',elapsed_time)\n",
    "    return final_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea60d032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 0.23521489500000037\n"
     ]
    }
   ],
   "source": [
    "# pass sample of test data for predictions:\n",
    "predictions = process_data(in_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50e2b0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [0.01041864]\n"
     ]
    }
   ],
   "source": [
    "print('predictions',predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295e1c66",
   "metadata": {},
   "source": [
    "##   5 regr_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bbdc7a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regr_metric(test_sampl,y_pred):\n",
    "    ''' \n",
    "    Calculate & print regresion metrics\n",
    "    '''\n",
    "    #\n",
    "    submit_df=pd.DataFrame()\n",
    "    submit_df['fullVisitorId']=test_sampl['fullVisitorId']\n",
    "    submit_df['PredictedLogRevenue'] = y_pred\n",
    "    #\n",
    "    test_df =  test_sampl[['fullVisitorId','totals.totalTransactionRevenue'] ] \n",
    "    test_df['totals.totalTransactionRevenue'].fillna(0, inplace=True) \n",
    "    test_grp= test_df.groupby('fullVisitorId')\\\n",
    "           ['totals.totalTransactionRevenue'].sum().apply(np.log1p,ais=1).reset_index()\n",
    "    test_grp = pd.merge(test_grp,submit_df,on='fullVisitorId')\n",
    "    rms= np.sqrt(metrics.mean_squared_error(test_grp['totals.totalTransactionRevenue'],\n",
    "                                        test_grp['PredictedLogRevenue']))\n",
    "    map = metrics.mean_absolute_error(test_grp['totals.totalTransactionRevenue'],test_grp['PredictedLogRevenue'])\n",
    "    print('mean_squared_error  =',rms)\n",
    "    print('mean_absolute_error =',map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "58c62eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error  = 0.010418636002181562\n",
      "mean_absolute_error = 0.010418636002181562\n"
     ]
    }
   ],
   "source": [
    "regr_metric(in_point,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928367d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
